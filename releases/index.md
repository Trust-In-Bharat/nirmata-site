# TRUST-IN Bharat  
### Powered by the NIRMATA Framework  
**National Information Risk Maturity and Trust Assessment**

---

## Executive Overview

**TRUST-IN Bharat (Trusted Resilience and Unified Security Transformation for India)** is a national self-assessment and improvement initiative helping Indian organizations **measure, improve, and demonstrate trustworthiness** in data-security, privacy, and responsible-AI governance.  

At its core lies **NIRMATA — National Information Risk Maturity and Trust Assessment**, a structured, evidence-driven model defining how enterprises progress from *unaware* to *resilient*.  
Together they advance India’s vision of a secure, privacy-respecting, and innovation-ready Digital Bharat.

---

## 1  Introduction & Rationale

India’s digital economy faces a dual challenge: rapidly increasing data volume and evolving regulatory expectations (DPDP Act 2023, CERT-In Directions 2022).  
Existing global frameworks (ISO 27001, 27701, 42001; NIST CSF 2.0) provide strong guidance yet lack localized maturity measurement and MSME accessibility.  

**NIRMATA** fills this gap by providing:
- A single Indian maturity reference model.  
- A crosswalk with global standards.  
- Scalable guidance for enterprises of all sizes.  
- Open, evidence-based benchmarking.

---

## 2  Design Principles

1. **Trust by Design** — embed security and privacy from inception.  
2. **Privacy by Design** — DPDP-aligned lifecycle controls and grievance readiness.  
3. **Resilience by Default** — measurable, auditable, continuously improved controls.  
4. **Simplicity and Clarity** — accessible to MSME founders and non-technical managers.  
5. **Interoperability** — mapped to ISO / NIST / CERT-In / DPDP cross-references.

---

## 3  The Twelve NIRMATA Domains (Pillars of Trust)

| # | Domain | Purpose |
|--:|:--|:--|
| 1 | Governance & Accountability | Define ownership, oversight, funding, and tone from the top. |
| 2 | Risk Management | Identify, assess, and mitigate risks across IT, OT, and privacy. |
| 3 | Compliance Management | Ensure adherence to laws, regulations, and standards. |
| 4 | Data Lifecycle & Classification | Label, retain, and delete data responsibly. |
| 5 | Access & Identity Management | Control who has access and why. |
| 6 | Operational Technology & IoT Security | Secure industrial assets and connected devices. |
| 7 | Vendor & Supply-Chain Governance | Extend trust to partners and suppliers. |
| 8 | Incident Response & Continuity Management | Detect, report, and recover from incidents. |
| 9 | Privacy Operations | Operationalize DPDP requirements and data-subject rights. |
| 10 | Culture & Workforce Awareness | Build human resilience through training and behavior. |
| 11 | Metrics, Monitoring & Continuous Improvement | Measure performance and drive learning. |
| 12 | AI Governance & Ethical Use | Ensure responsible AI design, use, and oversight. |

Each domain includes measurable indicators across six maturity levels (0–5).

---

## 4  The NIRMATA Maturity Model (0 – 5)

| Level | Label | Description |
|--:|:--|:--|
| 0 | Non-existent / Unaware | No ownership or process exists. |
| 1 | Initial / Reactive | Isolated responses after incidents. |
| 2 | Defined / Planned | Policies and roles documented but not operational. |
| 3 | Implemented / Managed | Processes partially operational and reviewed. |
| 4 | Measured / Integrated | Controls monitored, quantified, and improved. |
| 5 | Resilient / Trusted | Embedded culture of continuous assurance and benchmarking. |

Levels 0–3 may be self-certified; Levels 4–5 require independent verification (see Section 8).

---

## 5  Scoring and Interpretation Framework

### 5.1 Overview
Each question within a domain is scored 0–5 using the response definitions in Section 5.2.  
Weighted averages produce domain scores, further adjusted by **Evidence Confidence Factor (ECF)** to account for proof strength (High = 1.0, Medium = 0.8, Low = 0.5).

---

### 5.2 Question Response Scale (0–5)

| Score | Label | Definition | Typical Evidence |
|--:|:--|:--|:--|
| 0 | Not Implemented / Unaware | No activity or ownership. | No records or policies. |
| 1 | Initiated / Reactive | Ad-hoc reaction to events. | Emails, one-off fixes. |
| 2 | Defined / Planned | Policy drafted; implementation pending. | Approved plans, budget notes. |
| 3 | Partially Implemented / Operational in Parts | Active in limited areas. | Pilot evidence, partial logs. |
| 4 | Implemented & Monitored | Deployed enterprise-wide, measured. | Metrics, dashboards, internal audit. |
| 5 | Institutionalized / Optimized | Fully embedded and externally verified. | Certifications, benchmarks. |

---

### 5.3 Computation Logic

1. Assign numeric value (0–5) to each question.  
2. Domain Score = Σ(question scores) / n.  
3. Weighted Domain Score = Domain Score × Domain Weight / 100.  
4. Apply ECF (0.5–1.0).  
5. Overall Maturity = Σ(all weighted scores × ECF).  
6. Map final score to nearest integer level (0–5).  

Radar visualizations display domain distribution; low-scoring sectors become improvement priorities.

---

### 5.4 Confidence Guidance

| Confidence Level | Criteria | Multiplier |
|:--|:--|:--:|
| High | Evidence verified internally or externally | 1.0 |
| Medium | Documentary proof partial | 0.8 |
| Low | Verbal assertion only | 0.5 |

---

### 5.5 Illustrative Interpretation

**Example Domain — Risk Management**  
Scores = 5, 3, 3, 4 → Average 3.75 (Level 3: Implemented).  
Weight 10 % → Contribution 0.375.  
ECF = 0.8 → Adjusted 0.30.  

---

### 5.6 Alignment with Global Frameworks

| Model | Equivalent Range |
|:--|:--|
| CMMI v2.0 | Levels 1–5 ≈ NIRMATA 0–5 |
| NIST CSF 2.0 | Tiers 1–4 ≈ Levels 2–5 |
| ISO 27001 Clauses 9–10 | Levels 4–5 |

---

## 6  Sectoral Calibration — Manufacturing Pilot Model

*(Includes MSME, Mid-Size, and Large Enterprises; 10 pages of detail covering risk landscape, weights, and evidence expectations.  
Refer to approved Section 7 text for full tables and citations to ENISA ETL 2025, DBIR 2025, X-Force 2025, Dragos 2025, Picus Blue 2025, DPDP Act 2023, CERT-In 2022.)*

---

## 7  Governance and Stewardship Framework

*(Full governance model as approved — roles of Elytra Security, verifiers, sector councils, ethics panel, versioning, and open-license governance.)*

---

## 8  Implementation Roadmap and National Adoption Pathway

*(Phased plan 2025–2028 — foundation, scale-up, verification, recognition; portal timeline, KPIs, risk mitigation, and policy alignment as approved.)*

---

## 9  References and Annexes

*(Full verified reference list — ENISA ETL 2025 [R1], DBIR 2025 [R2], IBM X-Force 2025 [R3], Dragos 2025 [R4], Picus Blue 2025 [R5], NIST CSF 2.0 [R6], ISO 27001/27701/42001 [R7–R9], DPDP Act 2023 [I1], CERT-In 2022 [I2], plus Annex summaries A–E.)*

---

## 10  Custodian Statement

> **Elytra Security**, as the founding custodian of the NIRMATA Framework and TRUST-IN Bharat Programme, commits to maintaining the framework as a public-interest, open-access standard under the Creative Commons Attribution-ShareAlike 4.0 License.   
> The initiative will remain neutral, evidence-driven, and subject to independent peer review.   
> Through this approach, India builds not just cybersecurity capacity but a **national architecture of digital trust.**

---

## 11  Acknowledgements

This first edition draws on insights from India’s cybersecurity, privacy, and AI-governance community — practitioners, academics, and industry leaders who believe that trust is a national asset.  

**Programme:** TRUST-IN Bharat  **Framework:** NIRMATA  
**Custodian:** Elytra Security  **License:** CC BY-SA 4.0  
**Email:** trustin@elytrasecurity.com  **Website:** <https://elytrasecurity.com/trustin>  

---

*(End of Document — TRUST-IN Bharat / NIRMATA Framework Whitepaper v1.0 – 2025)* 
